apiVersion: v1
kind: Pod
metadata:
  name: gpu-test-pod
  namespace: gpu-operator-system
  labels:
    app: gpu-test
spec:
  restartPolicy: Never
  containers:
  - name: cuda-container
    image: nvcr.io/nvidia/cuda:11.8.0-base-ubuntu22.04
    command: ["nvidia-smi"]
    resources:
      limits:
        nvidia.com/gpu: 1
---
apiVersion: batch/v1
kind: Job
metadata:
  name: gpu-stress-test
  namespace: gpu-operator-system
  labels:
    app: gpu-stress-test
spec:
  parallelism: 1
  completions: 1
  backoffLimit: 3
  template:
    metadata:
      labels:
        app: gpu-stress-test
    spec:
      restartPolicy: Never
      containers:
      - name: gpu-burn
        image: oguzpastirmaci/gpu-burn:latest
        args: ["60"]  # Run for 60 seconds
        resources:
          limits:
            nvidia.com/gpu: 1
          requests:
            nvidia.com/gpu: 1
            memory: "2Gi"
            cpu: "1000m"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gpu-workload-sample
  namespace: gpu-operator-system
  labels:
    app: gpu-workload-sample
spec:
  replicas: 1
  selector:
    matchLabels:
      app: gpu-workload-sample
  template:
    metadata:
      labels:
        app: gpu-workload-sample
    spec:
      containers:
      - name: cuda-workload
        image: tensorflow/tensorflow:latest-gpu
        command: ["/bin/bash", "-c", "--"]
        args: ["while true; do sleep 30; done;"]
        env:
        - name: NVIDIA_VISIBLE_DEVICES
          value: "all"
        - name: NVIDIA_DRIVER_CAPABILITIES
          value: "compute,utility"
        resources:
          requests:
            memory: "4Gi"
            cpu: "2000m"
            nvidia.com/gpu: 1
          limits:
            memory: "8Gi"
            cpu: "4000m"
            nvidia.com/gpu: 1